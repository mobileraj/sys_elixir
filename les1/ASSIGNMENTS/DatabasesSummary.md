*Insert intro here*

First, the client connects to the relational DBMS through the client communications manager, which facilitates sessions, requests, and responds. Queries are then passed to the process manager. The process manager creates, schedules, and manages the workers of the DBMS. A worker will use the relational query processor (RQP) to compile and execute its SQL query. The RQP calls the transactional storage manager. The transactional store manager obtains and manipulates data as specified by the query. From here, the stack unwinds. Data and computations bubble up the stack until the results of the query, polished and organized, are sent back to the client. This represents the standard life of a query; client sends a message, message is processed, and data is returned back to the client. 

The client communications manager is the first tier in an RDBMS. This tier is responsible for (1) creating and maintaining sessions with clients; (2) receiving and delegating requests to the rest of the database; (3) responding to clients with query results. After the client communications manager creates a session with the client, the process model must create, schedule, and maintain a worker which is responsible for handling the clients queries. The RDBMS must ultimately transfer data to and from the client. To do this, it employs two main buffers: the I/O buffer for the disk, and a communications buffer for queueing client data. The disk buffer writes to and reads from both the database and the query logs. The communications buffer is used when the client is fetching data in small chunks. The RDBMS, anticipating the client's future requests of the data, loads it into this buffer. These buffers are necessary for data transfer and manipulation, from client to server to client.

Often, RDBMS's are implemented around one of three main process models for creating workers. The first model creates an OS process for each worker. This model was often used in early RDBMS’s due to the lack of efficient and effective support for OS threads. Due to the isolated nature of processes, process-based workers are relatively easy to implement, as many of the common problems and bugs in multithreading only arise when using shared environments and resources. However, OS processes are expensive to create. The second model uses a process pool to limit the number of processes. Processes are reused instead of re-created. Thus, this model tends to be far more resource efficient than the first model. Latency problems arise, however, when there are not enough processes in the pool to handle the incoming requests. The final model speeds things up by running workers in threads instead of processes. Threads (whether they are OS threads or special DBMS-implemented threads) are much cheaper to create than processes and tend to be faster. However, due to the fact that threads share memory, multithreading introduces many possible bugs to the system, such as race conditions. This makes such systems much harder to implement correctly. Each process model comes with its own pros and cons. Often, an RDBMS will implement multiple strategies to provide the best performance and scalability.

There are three major parallelism models: the Shared-Memory, Shared-Disk, and Shared-Nothing models. In the Shared-Memory, multiple CPUs use the same RAM and Disk memory. The simplicity of this model is attractive; the DBMS as a whole behaves like a single multiprocessor device. All three process models (covered in the last paragraph) become easy to implement. Multiple independent SQL requests can be ran in parallel, or single complex queries can be be parallelized. Coordinating between CPUs is easy. However, if one device shuts down, the whole system will typically shut down as well, due to the interconnected nature of the CPUs. An alternative is the Shared-Disk model. Similarly to the previous, long-term disk memory is shared; RAM memory, however, is kept separate with each CPU. This model comes with the important benefit that the failure of one machine will not necessarily affect the others, and thus the DBMS can continue running in the event of a single CPU failure. However, coordination between devices can be difficult, as there is no shared RAM memory. Thus, systems with these models need two additional components: a distributed lock manager, and a protocol to manage the distributed, buffered caches. Shared-Memory and Shared-Disk models both come with the vulnerability to data corruption. In the third model, Shared-Nothing, a group of independent machines are used to run the DBMS. As the name implies, no memory is shared; data is communicated through message passing. Tables are stored piecewise throughout the various machines. A single query may will be run in part on all machines, the results of which are then aggregated. This allows for even load-balancing. Overall, this model tends to be highly scalable, as each processor can be considered its own machine. However, there are two main problems: complex cross-processor coordination is required, as they do not have shared memory. In addition, although one machine's failure may not affect directly affect the others, part of the database will become unavailable (given the partitioning scheme described). Thus, redundancy is required for reliability. As with the three process models, commercial DBMSs will typically use a hybrid of all three of these models, given their pros and cons. 

The relational query processor (RQP) is responsible for validating, optimizing, and executing SQL queries. The RQP has five main components: the SQL parser, the query rewriter, the query optimizer, the query executor, and the access methods to the disk data structures. When the RQP receives SQL, the first step is the parse it. Table and column names/aliases are resolved, authentication is verified (which includes ensuring that no constraints are violated), and the original SQL is converted into an internal representation of the query. Next, the query (or, more likely, the internal representation of the query) is rewritten to make query optimization easier. The main (and original) function of this phase is to expand logical views into their corresponding real tables in the database. In addition, expressions are simplified (constant arithmetic, always-false conditions, etc) or expanded (e.g., to include implicit predicates). The query is flattened into SELECT-FROM-WHERE blocks; this makes query optimization much simpler, as the optimizer does not have to untangle deeply nested queries. 

Once the query is rewritten, the optimizer turns that query into a plan/dataflow. This dataflow can be represented as an expression tree of low-level database operators. To create this tree of operators, the query optimizer uses many complex algorithms and heuristics to achieve the desired query in the most efficient manner possible. The optimizer transforms the declarative query into a tree of imperative commands, to be traversed by the query executor. The query executor will typically use a model based on iterators. Iterators represent a nodes. Each iterator stores 1) its input iterators; 2) a method for generating the next resulting tuple based on the tuples generated by its inputs. Both output and input tuples are 1) stored either in a buffer pool (reference counted), or in a memory heap; and 2) referenced by the iterators using a "tuple descriptor", which typically contains either the physical address of the tuple or the primary key of a row in the database.  To generate the next resulting tuple, the root iterator must recursively generate the tuple from all its input iterators. Generating the next tuple of an iterator can be represented as a typical procedure on the call stack. The plan at a high-level describes the data flow, and iterators follow this plan in the control flow. Those four components describe how SQL is turned into query results. The final component is the access methods of the query. These are routines that manage access to the data structures on the disk (such as heaps and trees). They provide the concrete implementations of iterators.

